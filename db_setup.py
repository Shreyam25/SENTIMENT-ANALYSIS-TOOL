# -*- coding: utf-8 -*-
"""DB_SETUP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uoww2K1KVXFZnGRcETvbPRk-xyNNL9ZO
"""



import pandas as pd
file_path = '/content/drive/MyDrive/IMDB Dataset.csv'
df = pd.read_csv(file_path)
df.head()

df.info()

!pip install contractions emoji

import nltk
from nltk.corpus import stopwords
from contractions import fix
from nltk.stem import PorterStemmer
import emoji

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

# Function to remove HTML tags
def remove_html_tags(text):
    import re
    return re.sub(r'<.*?>', '', text)

# Function to remove punctuation
def remove_punctuation(text):
    import string
    return text.translate(str.maketrans('', '', string.punctuation))

# Function to convert text to lowercase
def lowercase_text(text):
    return text.lower()

# Function to remove extra whitespaces
def remove_extra_whitespace(text):
    return ' '.join(text.split())

# Function to expand contractions
def expand_contractions(text):
    return fix(text)

# Function to apply stemming
def apply_stemming(text):
    return ' '.join(stemmer.stem(word) for word in text.split())

# Function to replace emojis with text descriptions
def replace_emojis(text):
    return emoji.demojize(text, delimiters=("", " "))

# Function to remove stopwords
def remove_stopwords(text):
    return ' '.join(word for word in text.split() if word not in stop_words)

# Main cleaning function that applies all preprocessing steps
def clean_review(text):
    text = remove_html_tags(text)
    text = remove_punctuation(text)
    text = lowercase_text(text)
    text = remove_extra_whitespace(text)
    text = expand_contractions(text)
    text = replace_emojis(text)
    text = remove_stopwords(text)
    text = apply_stemming(text)
    return text
df['cleaned_review'] = df['review'].apply(clean_review)

df.drop_duplicates(subset='cleaned_review', inplace=True)
df.reset_index(drop=True, inplace=True)

# Exploratory stats (for verification)
def basic_stats(df):
    """Print basic statistics for the cleaned dataset."""
    print("Number of reviews:", len(df))
    print("Positive reviews:", len(df[df['sentiment'] == 'positive']))
    print("Negative reviews:", len(df[df['sentiment'] == 'negative']))
    avg_length = df['cleaned_review'].apply(len).mean()
    print("Average review length:", avg_length)

basic_stats(df)

df.head()

df = df.drop(columns=['review'])

# Save the cleaned dataset to a new CSV file
df.to_csv("cleaned_imdb_dataset.csv", index=False)
print("Cleaned data saved to cleaned_imdb_dataset.csv")

file_path = '/content/cleaned_imdb_dataset.csv'
df = pd.read_csv(file_path)
df.loc[2][1]

!pip install wordcloud

import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt

positive_reviews = df[df['sentiment'] == 'positive']['cleaned_review']
negative_reviews = df[df['sentiment'] == 'negative']['cleaned_review']

positive_text = ' '.join(positive_reviews)
negative_text = ' '.join(negative_reviews)

positive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_text)
negative_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(negative_text)

plt.figure(figsize=(12, 6))

# Positive word cloud
plt.subplot(1, 2, 1)
plt.imshow(positive_wordcloud, interpolation='bilinear')
plt.title('Positive Reviews Word Cloud')
plt.axis('off')

# Negative word cloud
plt.subplot(1, 2, 2)
plt.imshow(negative_wordcloud, interpolation='bilinear')
plt.title('Negative Reviews Word Cloud')
plt.axis('off')

plt.tight_layout()
plt.show()

"""

*   Positive reviews tend to focus on enjoyable aspects such as story, character,and the overall movie experience (e.g., "time", "show").
*   Negative reviews focus more on aspects that weren't satisfying, like look, think, and even, often expressing disappointment.


"""

import matplotlib.pyplot as plt
sentiment_distribution = df['sentiment'].value_counts()

df['review_length'] = df['cleaned_review'].apply(lambda x: len(x.split()))
average_review_length = df.groupby('sentiment')['review_length'].mean()

fig, ax = plt.subplots(1, 2, figsize=(16, 6))

ax[0].bar(sentiment_distribution.index, sentiment_distribution.values, color=['blue', 'red'])
ax[0].set_title('Number of Reviews per Sentiment')
ax[0].set_xlabel('Sentiment')
ax[0].set_ylabel('Number of Reviews')
ax[0].set_xticks(range(len(sentiment_distribution)))
ax[0].set_xticklabels(sentiment_distribution.index, rotation=0)

ax[1].bar(average_review_length.index, average_review_length.values, color=['blue', 'red'])
ax[1].set_title('Average Review Length by Sentiment')
ax[1].set_xlabel('Sentiment')
ax[1].set_ylabel('Average Review Length (in words)')
ax[1].set_xticks(range(len(average_review_length)))
ax[1].set_xticklabels(average_review_length.index, rotation=0)

plt.tight_layout()
plt.show()

"""Length of text is not having relationship with sentiment.

"""